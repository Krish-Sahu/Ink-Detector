{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\nsys.path.append('//kaggle/input/for-vesuvius/EfficientNet-PyTorch-master/EfficientNet-PyTorch-master')\nsys.path.append('/kaggle/input/for-vesuvius/pytorch-image-models-main/pytorch-image-models-main')\nsys.path.append('/kaggle/input/for-vesuvius/segmentation_models.pytorch-master/segmentation_models.pytorch-master')","metadata":{"execution":{"iopub.status.busy":"2023-06-07T11:01:30.914211Z","iopub.execute_input":"2023-06-07T11:01:30.915547Z","iopub.status.idle":"2023-06-07T11:01:30.921133Z","shell.execute_reply.started":"2023-06-07T11:01:30.915511Z","shell.execute_reply":"2023-06-07T11:01:30.919973Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy as sp\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\nimport matplotlib.pyplot as plt\nimport sys\nimport os\nimport gc\nimport sys\nimport pickle\nimport warnings\nimport math\nimport time\nimport random\nimport argparse\nimport importlib\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nimport segmentation_models_pytorch as smp\n#from warmup_scheduler import GradualWarmupScheduler\nimport cv2\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2023-06-07T11:01:32.371287Z","iopub.execute_input":"2023-06-07T11:01:32.371624Z","iopub.status.idle":"2023-06-07T11:01:41.165115Z","shell.execute_reply.started":"2023-06-07T11:01:32.371602Z","shell.execute_reply":"2023-06-07T11:01:41.164026Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py:255: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n  if block_type is 'proj':\n/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py:258: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n  elif block_type is 'down':\n/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4/pretrainedmodels/models/dpn.py:262: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n  assert block_type is 'normal'\n","output_type":"stream"}]},{"cell_type":"code","source":"import segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2023-06-07T11:04:28.890946Z","iopub.execute_input":"2023-06-07T11:04:28.891304Z","iopub.status.idle":"2023-06-07T11:04:28.897824Z","shell.execute_reply.started":"2023-06-07T11:04:28.891276Z","shell.execute_reply":"2023-06-07T11:04:28.896105Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    # ============== comp exp name =============\n    comp_name = 'vesuvius'\n    exp_name = 'mitb2'\n    comp_dir_path = '/kaggle/input/'\n    comp_folder_name = 'vesuvius-challenge-ink-detection'\n    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n\n    # ============== pred target =============\n    target_size = 1\n\n    # ============== model cfg =============\n    model_name = 'Unet'\n    backbone = 'mit_b2' #'se_resnext50_32x4d'\n\n    in_chans = 3 # 65\n    # ============== training cfg =============\n    size = 224\n    tile_size = 224\n    stride = tile_size // 2\n\n    train_batch_size = 16 # 32\n    valid_batch_size = train_batch_size * 2\n    use_amp = True\n\n    scheduler = 'GradualWarmupSchedulerV2' # 'GradualWarmupSchedulerV2' # 'CosineAnnealingLR'\n    epochs = 20 # 30\n\n    # adamW warmupあり\n    warmup_factor = 10\n    # lr = 1e-4 / warmup_factor\n    lr = 1e-4 / warmup_factor\n\n    # ============== fold =============\n    valid_id = [1]\n\n    # objective_cv = 'binary'  # 'binary', 'multiclass', 'regression'\n    metric_direction = 'maximize'  # maximize, 'minimize'\n    # metrics = 'dice_coef'\n\n    # ============== fixed =============\n    pretrained = True\n    inf_weight = 'best'  # 'best'\n    loss = \"FL\"\n\n    min_lr = 1e-7\n    weight_decay = 0.05\n    max_grad_norm = 1000\n\n    print_freq = 50\n    num_workers = 2\n\n    seed = 310\n    \n    # ============== set dataset path =============\n    print('set dataset path')\n\n    outputs_path = f'/kaggle/working/outputs/{comp_name}/{exp_name}/'\n\n    submission_dir = outputs_path + 'submissions/'\n    submission_path = submission_dir + f'submission_{exp_name}.csv'\n\n    model_dir = outputs_path + \\\n        f'{comp_name}-models/'\n\n    figures_dir = outputs_path + 'figures/'\n\n    log_dir = outputs_path + 'logs/'\n    log_path = log_dir + f'{exp_name}.txt'\n\n    # ============== augmentation =============\n#     train_aug_list = [\n#         A.Resize(size, size),\n#         A.HorizontalFlip(p=0.5),\n#         A.VerticalFlip(p=0.5),\n#         A.RandomBrightnessContrast(p=0.75),\n#         A.ShiftScaleRotate(p=0.75),\n#         A.OneOf([\n#                 A.GaussNoise(var_limit=[10, 50]),\n#                 A.GaussianBlur(),\n#                 A.MotionBlur(),\n#                 ], p=0.4),\n#         A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n#         A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n#                         mask_fill_value=0, p=0.5),\n#         A.Normalize(\n#             mean= [0] * in_chans,\n#             std= [1] * in_chans\n#         ),\n#         ToTensorV2(transpose_mask=True),\n#     ]\n    \n    train_aug_list = [\n    #A.RandomCrop(CFG.tile_size,CFG.tile_size),\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.SafeRotate(p = 0.3),\n    A.Transpose(p=0.3),\n    A.CoarseDropout(max_holes=8, max_height=int(size*0.1), max_width=int(size*0.1), min_holes=3, fill_value=0, mask_fill_value=0, p=0.5),\n    A.ElasticTransform(p = 0.2),\n    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n    A.Emboss(p = 0.1),\n    A.RandomBrightnessContrast(p=0.75),\n    A.RandomGridShuffle(grid=(4, 4), p = 0.3),\n    A.RingingOvershoot(p = 0.2),\n    A.GaussNoise(var_limit=(0.0, 40.0), per_channel=False, p=0.3),\n    A.GaussianBlur(p = 0.2),\n    A.Sharpen(p = 0.2),\n    A.Normalize(\n        mean= [0] * in_chans,\n        std= [1] * in_chans,\n    ),\n        ToTensorV2(transpose_mask=True),\n ]\n\n    valid_aug_list = [\n        A.Resize(size, size),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:56:57.155142Z","iopub.execute_input":"2023-06-07T10:56:57.155521Z","iopub.status.idle":"2023-06-07T10:56:57.177775Z","shell.execute_reply.started":"2023-06-07T10:56:57.155492Z","shell.execute_reply":"2023-06-07T10:56:57.173226Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"set dataset path\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, weight=None):\n        super().__init__()\n        self.cfg = cfg\n\n        self.encoder = smp.Unet(\n            encoder_name=cfg.backbone, \n            encoder_weights=weight,\n            in_channels=cfg.in_chans,\n            classes=cfg.target_size,\n            activation=None,\n        )\n\n    def forward(self, image):\n        output = self.encoder(image)\n        # output = output.squeeze(-1)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:56:26.081625Z","iopub.execute_input":"2023-06-07T10:56:26.082058Z","iopub.status.idle":"2023-06-07T10:56:26.089209Z","shell.execute_reply.started":"2023-06-07T10:56:26.082012Z","shell.execute_reply":"2023-06-07T10:56:26.088187Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def build_model(cfg, weight=\"imagenet\"):\n    print('model_name', cfg.model_name)\n    print('backbone', cfg.backbone)\n\n    model = CustomModel(cfg, weight)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:56:27.270995Z","iopub.execute_input":"2023-06-07T10:56:27.271371Z","iopub.status.idle":"2023-06-07T10:56:27.277241Z","shell.execute_reply.started":"2023-06-07T10:56:27.271341Z","shell.execute_reply":"2023-06-07T10:56:27.275929Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"IS_DEBUG = False\nmode = 'train' if IS_DEBUG else 'test'\nTH = 0.4","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model\n","metadata":{"execution":{"iopub.status.busy":"2023-06-07T10:57:03.533602Z","iopub.execute_input":"2023-06-07T10:57:03.534002Z","iopub.status.idle":"2023-06-07T10:57:03.539304Z","shell.execute_reply.started":"2023-06-07T10:57:03.533956Z","shell.execute_reply":"2023-06-07T10:57:03.537942Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def read_image(fragment_id):\n    images = []\n\n    # idxs = range(65)\n    mid = 65 // 2\n    start = mid - CFG.in_chans // 2\n    end = mid + CFG.in_chans // 2\n    idxs = range(start, end)\n\n    for i in tqdm(idxs):\n        \n        image = cv2.imread(CFG.comp_dataset_path + f\"{mode}/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n\n        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n\n        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n\n        images.append(image)\n    images = np.stack(images, axis=2)\n    \n    return images","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(data, cfg):\n    if data == 'train':\n        aug = A.Compose(cfg.train_aug_list)\n    elif data == 'valid':\n        aug = A.Compose(cfg.valid_aug_list)\n\n    # print(aug)\n    return aug\n\nclass CustomDataset(Dataset):\n    def __init__(self, images, cfg, labels=None, transform=None):\n        self.images = images\n        self.cfg = cfg\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        # return len(self.xyxys)\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        # x1, y1, x2, y2 = self.xyxys[idx]\n        image = self.images[idx]\n        data = self.transform(image=image)\n        image = data['image']\n        return image\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_test_dataset(fragment_id):\n    test_images = read_image(fragment_id)\n    \n    x1_list = list(range(0, test_images.shape[1]-CFG.tile_size+1, CFG.stride))\n    y1_list = list(range(0, test_images.shape[0]-CFG.tile_size+1, CFG.stride))\n    \n    test_images_list = []\n    xyxys = []\n    for y1 in y1_list:\n        for x1 in x1_list:\n            y2 = y1 + CFG.tile_size\n            x2 = x1 + CFG.tile_size\n            \n            test_images_list.append(test_images[y1:y2, x1:x2])\n            xyxys.append((x1, y1, x2, y2))\n    xyxys = np.stack(xyxys)\n            \n    test_dataset = CustomDataset(test_images_list, CFG, transform=get_transforms(data='valid', cfg=CFG))\n    \n    test_loader = DataLoader(test_dataset,\n                          batch_size=CFG.batch_size,\n                          shuffle=False,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    return test_loader, xyxys","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if mode == 'test':\n    fragment_ids = sorted(os.listdir(CFG.comp_dataset_path + mode))\nelse:\n    fragment_ids = [3]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\nfor fragment_id in fragment_ids:\n    \n    test_loader, xyxys = make_test_dataset(fragment_id)\n    \n    binary_mask = cv2.imread(CFG.comp_dataset_path + f\"{mode}/{fragment_id}/mask.png\", 0)\n    binary_mask = (binary_mask / 255).astype(int)\n    \n    ori_h = binary_mask.shape[0]\n    ori_w = binary_mask.shape[1]\n    # mask = mask / 255\n\n    pad0 = (CFG.tile_size - binary_mask.shape[0] % CFG.tile_size)\n    pad1 = (CFG.tile_size - binary_mask.shape[1] % CFG.tile_size)\n\n    binary_mask = np.pad(binary_mask, [(0, pad0), (0, pad1)], constant_values=0)\n    \n    mask_pred = np.zeros(binary_mask.shape)\n    mask_count = np.zeros(binary_mask.shape)\n\n    for step, (images) in tqdm(enumerate(test_loader), total=len(test_loader)):\n        images = images.to(device)\n        batch_size = images.size(0)\n\n        with torch.no_grad():\n            y_preds = model(images)\n\n        start_idx = step*CFG.batch_size\n        end_idx = start_idx + batch_size\n        for i, (x1, y1, x2, y2) in enumerate(xyxys[start_idx:end_idx]):\n            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n    \n    plt.imshow(mask_count)\n    plt.show()\n    \n    print(f'mask_count_min: {mask_count.min()}')\n    mask_pred /= mask_count\n    \n    mask_pred = mask_pred[:ori_h, :ori_w]\n    binary_mask = binary_mask[:ori_h, :ori_w]\n    \n    mask_pred = (mask_pred >= TH).astype(int)\n    mask_pred *= binary_mask\n    \n    plt.imshow(mask_pred)\n    plt.show()\n    \n    inklabels_rle = rle(mask_pred)\n    \n    results.append((fragment_id, inklabels_rle))\n    \n\n    del mask_pred, mask_count\n    del test_loader\n    \n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame(results, columns=['Id', 'Predicted'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = pd.read_csv('/kaggle/input/vesuvius-challenge-ink-detection/sample_submission.csv')\nsample_sub = pd.merge(sample_sub[['Id']], sub, on='Id', how='left')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]}]}